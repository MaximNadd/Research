{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":11346491,"datasetId":7099559,"databundleVersionId":11773686}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nibabel as nib\nimport random\nfrom scipy import ndimage\nimport time\nimport datetime\n\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Input, Conv3D, MaxPool3D, GlobalAveragePooling3D, Dense, Dropout, BatchNormalization, concatenate\nfrom tensorflow.keras.models import Model, load_model\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom keras.utils import plot_model\nfrom keras.metrics import AUC\nfrom tensorflow.keras.regularizers import l2\nfrom keras.utils import Sequence","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-10T00:38:38.077561Z","iopub.execute_input":"2025-04-10T00:38:38.077817Z","iopub.status.idle":"2025-04-10T00:39:02.833031Z","shell.execute_reply.started":"2025-04-10T00:38:38.077794Z","shell.execute_reply":"2025-04-10T00:39:02.832364Z"}},"outputs":[{"name":"stderr","text":"2025-04-10 00:38:41.702625: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1744245522.151629      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1744245522.284965      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# The following code will only execute\n# successfully when compression is complete\n\nimport kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"maximnaddaf/ct-multi-data\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T00:39:02.834447Z","iopub.execute_input":"2025-04-10T00:39:02.835103Z","iopub.status.idle":"2025-04-10T00:39:03.172580Z","shell.execute_reply.started":"2025-04-10T00:39:02.835068Z","shell.execute_reply":"2025-04-10T00:39:03.171798Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/ct-multi-data\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"def count_directories(path):\n    # List all items in the directory and filter for directories\n    return len([d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))])\n\n\ntest = \"/kaggle/input/ct-multi-data/Processed_CT_Scans/test/CT-0\"\ntest_2  = \"/kaggle/input/ct-multi-data/Processed_CT_Scans/test/CT-23\"\n\ntrain = \"/kaggle/input/ct-multi-data/Processed_CT_Scans/train/CT-0\"\ntrain_2  = \"/kaggle/input/ct-multi-data/Processed_CT_Scans/train/CT-23\"\n\nprint(f\"Number of directories in test (CT-0, CT-23): {count_directories(test)}, {count_directories(test_2)}\")\nprint(f\"Number of directories in train (CT-0, CT-23): {count_directories(train)}, {count_directories(train_2)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T00:43:05.069638Z","iopub.execute_input":"2025-04-10T00:43:05.069966Z","iopub.status.idle":"2025-04-10T00:43:07.056485Z","shell.execute_reply.started":"2025-04-10T00:43:05.069943Z","shell.execute_reply":"2025-04-10T00:43:07.055749Z"}},"outputs":[{"name":"stdout","text":"Number of directories in test (CT-0, CT-23): 172, 172\nNumber of directories in train (CT-0, CT-23): 860, 860\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"def load_nii(file_path):\n    return nib.load(file_path).get_fdata()\n\nclass MultiModalDataset(Sequence):\n    def __init__(self, patient_dirs, labels, batch_size, fold, shuffle=True):\n        self.patient_dirs = patient_dirs\n        self.labels = labels\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.fold = fold\n        self.indices = np.arange(len(self.patient_dirs))\n        self.on_epoch_end()\n\n    def __len__(self):\n        return int(np.floor(len(self.patient_dirs) / self.batch_size))\n\n    def __getitem__(self, index):\n        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n        batch_patient_dirs = [self.patient_dirs[i] for i in batch_indices]\n        batch_labels = [self.labels[i] for i in batch_indices]\n\n        # Load modalities\n        X = self.__load_modalities(batch_patient_dirs)\n        y = np.array(batch_labels)\n\n        X = tuple(tf.convert_to_tensor(x, dtype=tf.float32) for x in X)\n\n        return X, y\n\n    def on_epoch_end(self):\n        if self.shuffle:\n            np.random.shuffle(self.indices)\n\n    def __load_modalities(self, patient_dirs):\n        modalities = {'split_1': [], 'split_2': []}\n\n        for patient_dir in patient_dirs:\n            patient_name = os.path.basename(patient_dir)\n\n            split_1_path = os.path.join(patient_dir, 'split_part_1.nii')\n            split_2_path = os.path.join(patient_dir, 'split_part_2.nii')\n\n            # Load each modality\n            split_1 = load_nii(split_1_path)\n            split_2 = load_nii(split_2_path)\n\n            modalities['split_1'].append(split_1)\n            modalities['split_2'].append(split_2)\n\n\n        # Stack the modalities for each patient along the first axis (batch axis)\n        X = [\n            np.array(modalities['split_1']),\n            np.array(modalities['split_2']),\n        ]\n\n        return X\n\n\ndef load_data_from_folder(base_dir):\n    patient_dirs = []\n    labels = []\n\n    for class_name in [\"CT-0\", \"CT-23\"]:  # Only two known classes\n        class_path = os.path.join(base_dir, class_name)\n        if not os.path.isdir(class_path):\n            continue\n\n        label = 0 if class_name == \"CT-0\" else 1\n\n        for study_name in os.listdir(class_path):\n            study_path = os.path.join(class_path, study_name)\n            if os.path.isdir(study_path):\n                patient_dirs.append(study_path)\n                labels.append(label)\n\n    return np.array(patient_dirs), np.array(labels)\n\n# Load and shuffle train data\ntrain_dirs, train_labels = load_data_from_folder(\"train\")\ntrain_indices = np.arange(len(train_dirs))\nnp.random.shuffle(train_indices)\ntrain_dirs = train_dirs[train_indices]\ntrain_labels = train_labels[train_indices]\n\n# Load and shuffle test data\ntest_dirs, test_labels = load_data_from_folder(\"test\")\ntest_indices = np.arange(len(test_dirs))\nnp.random.shuffle(test_indices)\ntest_dirs = test_dirs[test_indices]\ntest_labels = test_labels[test_indices]\n\n# Create your dataset objects\ntrain_dataset = MultiModalDataset(train_dirs, train_labels, batch_size=16, fold=\"train\", shuffle=True)\ntest_dataset = MultiModalDataset(test_dirs, test_labels, batch_size=8, fold=\"test\", shuffle=True)\n\nX, y = train_dataset[0]\n\nfor modality, data in zip(['split_1', 'split_2'], X):\n    print(f\"Shape of {modality} modality: {data.shape}\")\n\nprint(f\"label: {y}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T00:52:35.633534Z","iopub.execute_input":"2025-04-10T00:52:35.633850Z","iopub.status.idle":"2025-04-10T00:52:39.175271Z","shell.execute_reply.started":"2025-04-10T00:52:35.633829Z","shell.execute_reply":"2025-04-10T00:52:39.174280Z"}},"outputs":[{"name":"stdout","text":"Shape of split_1 modality: (0,)\nShape of split_2 modality: (0,)\nlabel: []\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1744246359.130069      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1744246359.130993      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}