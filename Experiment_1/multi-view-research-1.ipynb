{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":30.776915,"end_time":"2025-03-21T01:39:31.730854","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-03-21T01:39:00.953939","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nibabel as nib\nfrom scipy import ndimage\nfrom scipy.ndimage import rotate, zoom\nimport zipfile\nimport random\nfrom keras.utils import get_file\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import Sequence","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-03-25T03:42:19.180820Z","iopub.execute_input":"2025-03-25T03:42:19.181149Z","iopub.status.idle":"2025-03-25T03:42:19.185937Z","shell.execute_reply.started":"2025-03-25T03:42:19.181124Z","shell.execute_reply":"2025-03-25T03:42:19.185024Z"},"id":"f281acdf","papermill":{"duration":14.035528,"end_time":"2025-03-21T01:39:17.502887","exception":false,"start_time":"2025-03-21T01:39:03.467359","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"url_1 = \"https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-0.zip\"\nurl_2 = \"https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-23.zip\"\n\n# Directory where the files will be stored\ncache_dir = os.getcwd()  # Current working directory\n\n# Download the first file\nfilename_1 = get_file(\"CT-0.zip\", url_1, cache_dir=cache_dir)\n\n# Download the second file\nfilename_2 = get_file(\"CT-23.zip\", url_2, cache_dir=cache_dir)\n\n# Make a directory to store the data\nos.makedirs(\"MosMedData\", exist_ok=True)  # Using exist_ok=True to avoid errors if the directory exists\n\n# Unzip the first file\nwith zipfile.ZipFile(filename_1, \"r\") as z_fp:\n    z_fp.extractall(\"./MosMedData/\")\n\n# Unzip the second file\nwith zipfile.ZipFile(filename_2, \"r\") as z_fp:\n    z_fp.extractall(\"./MosMedData/\")","metadata":{"id":"442bcd7a","outputId":"df85262d-4b0b-4f54-b965-94fef5f6bd63","papermill":{"duration":0.044248,"end_time":"2025-03-21T01:39:29.144330","exception":false,"start_time":"2025-03-21T01:39:29.100082","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for dirpath, dirnames in os.walk(\"MosMedData\"):\n  print(f\"There are {len(dirnames)} directories in '{dirpath}'.\")","metadata":{"id":"set7B1cym9Zr","outputId":"03a1222c-eb2a-415b-b632-bf95475896ba","trusted":true,"execution":{"iopub.status.busy":"2025-03-25T03:42:09.472460Z","iopub.execute_input":"2025-03-25T03:42:09.472850Z","iopub.status.idle":"2025-03-25T03:42:09.476983Z","shell.execute_reply.started":"2025-03-25T03:42:09.472819Z","shell.execute_reply":"2025-03-25T03:42:09.476084Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import shutil\n\n# # Path to the directory to be deleted\n# directory_path_ct23 = '/content/MosMedData/CT-23'\n# directory_path_ct0 = '/content/MosMedData/CT-0'\n\n# # Delete the directory and all its contents\n# shutil.rmtree(directory_path_ct23)\n# shutil.rmtree(directory_path_ct0)","metadata":{"id":"VQw3Se0UVaVy"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to load a .nii.gz file\ndef load_nii(file_path):\n    return nib.load(file_path).get_fdata()\n\ndef save_nii(volume, save_path):\n    new_img = nib.Nifti1Image(volume, np.eye(4))  # Assuming the affine matrix is identity\n    nib.save(new_img, save_path)\n\n# Function to apply a random rotation to the volume\ndef random_rotate(volume):\n    angle = random.uniform(0, 360)\n    return rotate(volume, angle, axes=(0, 1), reshape=False)  # Rotate around the first two axes\n\n# Function to apply random zoom to the volume\ndef random_zoom(volume):\n    zoom_factor = random.uniform(0.8, 1.2)  # Random zoom factor between 0.8x and 1.2x\n    return zoom(volume, zoom_factor)\n\ndef normalize(volume):\n    \"\"\"Normalize the volume\"\"\"\n    min = -1000\n    max = 400\n    volume[volume < min] = min\n    volume[volume > max] = max\n    volume = (volume - min) / (max - min)\n    volume = volume.astype(\"float32\")\n    return volume\n\ndef resize_volume(img):\n    \"\"\"Resize across z-axis\"\"\"\n    # Set the desired depth\n    desired_depth = 64\n    desired_width = 128\n    desired_height = 128\n    \n    # Get current depth\n    current_depth = img.shape[-1]\n    current_width = img.shape[0]\n    current_height = img.shape[1]\n\n    # Compute depth factor\n    depth = current_depth / desired_depth\n    width = current_width / desired_width\n    height = current_height / desired_height\n    depth_factor = 1 / depth\n    width_factor = 1 / width\n    height_factor = 1 / height\n\n    # Resize across z-axis\n    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n    return img\n\ndef process_scan(path):\n    \"\"\"Read and resize volume\"\"\"\n    # Read scan\n    volume = load_nii(path)\n    # Normalize\n    volume = normalize(volume)\n    # Resize width, height and depth\n    volume = resize_volume(volume)\n    return volume\n\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_multiview_dataset(base_path, ct_folders):\n    for ct_folder in ct_folders:\n        folder_path = os.path.join(base_path, ct_folder)\n        # List all items in the folder and process only files (not directories)\n        for item in os.listdir(folder_path):\n            item_path = os.path.join(folder_path, item)\n\n            # Skip hidden files (those starting with a dot) and directories\n            if item.startswith('.') or os.path.isdir(item_path):\n                continue  # Skip hidden files or directories\n\n            if os.path.isfile(item_path) and item.endswith('.nii.gz'):  # Check if it's a .nii.gz file\n                try:\n                    # Load the original CT scan image\n                    original_volume = load_nii(item_path)\n\n                    # Create subdirectory for each file (based on the file name without extension)\n                    study_dir_name = os.path.splitext(item)[0]  # Get the file name without extension\n                    study_save_dir = os.path.join(folder_path, study_dir_name)\n                    os.makedirs(study_save_dir, exist_ok=True)\n\n                    # Save the original image\n                    save_nii(original_volume, os.path.join(study_save_dir, f\"{study_dir_name}_original.nii.gz\"))\n\n                    # Save the rotated image\n                    rotated_volume = random_rotate(original_volume)\n                    save_nii(rotated_volume, os.path.join(study_save_dir, f\"{study_dir_name}_rotated.nii.gz\"))\n\n                    # Save the zoomed-in image\n                    zoomed_volume = random_zoom(original_volume)\n                    save_nii(zoomed_volume, os.path.join(study_save_dir, f\"{study_dir_name}_zoom.nii.gz\"))\n\n                except Exception as e:\n                    print(f\"Error processing {item_path}: {e}\")\n\n# Directory structure\nbase_directory = \"MosMedData\"\nct_folders = [\"CT-0\", \"CT-23\"]\n\n# Create multi-view dataset\ncreate_multiview_dataset(base_directory, ct_folders)\n","metadata":{"id":"ELCziUn-4q-1"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def count_directories(path):\n    # List all items in the directory and filter for directories\n    return len([d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))])\n\n# Example usage:\npath = \"MosMedData/CT-23\"\npath2 = \"MosMedData/CT-0\"\nprint(f\"Number of directories: {count_directories(path2)}\")\nprint(f\"Number of directories: {count_directories(path)}\")","metadata":{"id":"xLb2CSHlBlx2","outputId":"ff582bab-7c6f-4db1-e952-cb28341dac17"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_path = './MosMedData/CT-0'\n\n# Iterate through the files in MosMedData\nfor item in os.listdir(base_path):\n    item_path = os.path.join(base_path, item)\n\n    # Check if it's a file and if it ends with '.gz'\n    if os.path.isfile(item_path) and item.endswith('.gz'):\n        os.remove(item_path)  # Delete the file\n        print(f\"Deleted file: {item_path}\")","metadata":{"id":"flmWMeWaPXaA","outputId":"bad6cddf-5d40-4b1b-a01e-6f9288074623"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Number of directories: {count_directories(path2)}\")\nprint(f\"Number of directories: {count_directories(path)}\")","metadata":{"id":"LZwG0EWem5Qc","outputId":"68c2531b-0c9e-4193-e49b-9dbc5d1993de"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MultiModalDataset(Sequence):\n    def __init__(self, patient_dirs, labels, batch_size, shuffle=True):\n        self.patient_dirs = patient_dirs\n        self.labels = labels\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.indices = np.arange(len(self.patient_dirs))\n        self.on_epoch_end()\n\n    def __len__(self):\n        return int(np.floor(len(self.patient_dirs) / self.batch_size))\n\n    def __getitem__(self, index):\n        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n        batch_patient_dirs = [self.patient_dirs[i] for i in batch_indices]\n        batch_labels = [self.labels[i] for i in batch_indices]\n        \n        # Load modalities\n        X = self.__load_modalities(batch_patient_dirs)\n        y = np.array(batch_labels)\n        \n        return X, y\n\n    def on_epoch_end(self):\n        if self.shuffle:\n            np.random.shuffle(self.indices)\n\n    def __load_modalities(self, patient_dirs):\n        modalities = {'original': [], 'rotated': [], 'zoom': []}\n        \n        for patient_dir in patient_dirs:\n            patient_name = os.path.basename(patient_dir)\n        \n            original = process_scan(os.path.join(patient_dir, f'{patient_name}_original.nii.gz'))\n            rotated = process_scan(os.path.join(patient_dir, f'{patient_name}_rotated.nii.gz'))\n            zoomed = process_scan(os.path.join(patient_dir, f'{patient_name}_zoom.nii.gz'))\n                        \n            # Append to the list for the batch\n            modalities['original'].append(original)\n            modalities['rotated'].append(rotated)\n            modalities['zoom'].append(zoomed)\n        \n        # Stack the modalities for each patient along the first axis (batch axis)\n        X = [\n            np.array(modalities['original']),\n            np.array(modalities['rotated']),\n            np.array(modalities['zoom'])\n        ]\n        \n        return X\n\n# Define the paths to your directories\nhealthy_dir = './MosMedData/CT-0'\nnon_healthy_dir = './MosMedData/CT-23'\n\n# List all patient directories (assuming each patient has a folder in each group)\nhealthy_patients = [os.path.join(healthy_dir, f) for f in os.listdir(healthy_dir) if os.path.isdir(os.path.join(healthy_dir, f))]\nnon_healthy_patients = [os.path.join(non_healthy_dir, f) for f in os.listdir(non_healthy_dir) if os.path.isdir(os.path.join(non_healthy_dir, f))]\n\n# Initialize lists to hold the data and labels\npatient_dirs = []  # Will hold paths to the patient directories\nlabels = []  # Will hold the labels (0 for healthy, 1 for non-healthy)\n\n# Load the data from healthy patients\nfor patient in healthy_patients:\n    patient_dirs.append(patient)\n    labels.append(0)  # Label 0 for healthy\n\n# Load the data from non-healthy patients\nfor patient in non_healthy_patients:\n    patient_dirs.append(patient)\n    labels.append(1)  # Label 1 for non-healthy\n\n# Convert to NumPy arrays\npatient_dirs = np.array(patient_dirs)\nlabels = np.array(labels)\n\n# Shuffle the data\nindices = np.arange(len(patient_dirs))\nnp.random.shuffle(indices)\n\npatient_dirs = patient_dirs[indices]\nlabels = labels[indices]\n\n# Split the data into training and testing sets (80/20)\npatient_dirs_train, patient_dirs_test, labels_train, labels_test = train_test_split(patient_dirs, labels, test_size=0.2, random_state=42)\n\n# Create the training and testing dataset objects\ntrain_dataset = MultiModalDataset(patient_dirs_train, labels_train, batch_size=1, shuffle=True)\ntest_dataset = MultiModalDataset(patient_dirs_test, labels_test, batch_size=1, shuffle=False)\n\n# Check the length of the datasets\nprint(f\"Train Dataset Length: {len(train_dataset)}\")\nprint(f\"Test Dataset Length: {len(test_dataset)}\")\nprint(f\"Labels Dataset Length: {len(labels)}\")\n\nprint(\"\\n\")\n\nX, y = train_dataset[0]\n\nfor modality, data in zip(['original', 'rotated', 'zoom'], X):\n    print(f\"Shape of {modality} modality: {data.shape}\")\n    \nprint(f\"label: {y}\")\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}